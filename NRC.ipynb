{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3eeb2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install NRCLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c66945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ellietupin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ellietupin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/zvz37scs6vj6_wyjn348qj800000gn/T/ipykernel_63069/2157958156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLeXmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeXmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import requests\n",
    "from LeXmo import LeXmo\n",
    "from preprocessing import processing\n",
    "import pickle\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import statsmodels.formula.api as sm\n",
    "from scipy.stats import t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bba00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import earning calls\n",
    "tickers = [\"AAPL\",\"MMM\"]\n",
    "\n",
    "texts = []\n",
    "list_ids = []\n",
    "Ticker = []\n",
    "number_texts_per_stock = []\n",
    "for ticker in tickers:\n",
    "    dir_path = \"data/text/\"+ticker+\"/\"\n",
    "    list_ids1 = os.listdir(dir_path)\n",
    "    ticker1 = os.path.basename(os.path.dirname(dir_path))\n",
    "    ticker1 = ticker1.split()\n",
    "    texts1 = []\n",
    "    for s in list_ids1:\n",
    "        with open(dir_path + s, encoding = 'ISO-8859-1') as f:\n",
    "            t = f.read()\n",
    "            texts1.append(t)\n",
    "    texts = texts + texts1\n",
    "    list_ids = list_ids + list_ids1 \n",
    "    Ticker = Ticker + ticker1*len(list_ids1)\n",
    "    number_texts_per_stock.append(len(list_ids1))\n",
    "print(len(texts))\n",
    "print(len(list_ids))\n",
    "print(len(Ticker))\n",
    "print(number_texts_per_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee70d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dates\n",
    "data_path = \"data/ticker/id_to_date\"\n",
    "with open(data_path,\"rb\") as file :\n",
    "    id_to_date = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with earning calls informations\n",
    "df1 = pd.DataFrame(data={'id': list_ids})\n",
    "df1['date']=list_ids\n",
    "df1=df1.replace({'date': id_to_date})\n",
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "df1['quarter'] = df1['date'].dt.to_period('Q')\n",
    "df1['ticker']= Ticker\n",
    "df1=df1.replace({'ticker': id_to_date})\n",
    "df1= df1.sort_values(['ticker','date'], ascending=True)\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do : keep same sumber of raws for each stock\n",
    "## For the moment : only 2 stocks of same lenghth so ok!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390ba2e",
   "metadata": {},
   "source": [
    "# Import datas from yahoo finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac2a2e",
   "metadata": {},
   "source": [
    "Import html tickers from data/ticker\n",
    "dir_path = \"data/ticker/\"\n",
    "list_tickers = os.listdir(dir_path)\n",
    "list_tickers.remove('.DS_Store') # for mac\n",
    "list_tickers.remove('id_to_date')\n",
    "print(list_tickers)\n",
    "\n",
    "Test with few stocks\n",
    "list_tickers = ['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeffdee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the month from which we import\n",
    "# Q1 : from january (1) to march (3)\n",
    "# Q2 : from april (4) to june (6)\n",
    "# Q3 : from july (7) to septmber (9)\n",
    "# Q4 : from october (10) to december (12)\n",
    "\n",
    "quarter_start = df1['quarter'].iloc[0].quarter\n",
    "month_start = quarter_start*2-1\n",
    "quarter_end = df1['quarter'].iloc[-2].quarter # take the last quarter\n",
    "month_end = quarter_end*3\n",
    "\n",
    "if month_end in [3,12]:\n",
    "    day_end = 31\n",
    "else:\n",
    "    day_end = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052eb5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "\n",
    "start = datetime.datetime(df1['date'].iloc[0].year,month_start,1)\n",
    "end   = datetime.datetime(df1['date'].iloc[-1].year,month_end,day_end)\n",
    "\n",
    "# create empty dataframe\n",
    "stock_final = pd.DataFrame()\n",
    "# iterate over each symbol\n",
    "list_tickers = list(set(Ticker))\n",
    "for i in list_tickers:  \n",
    "    \n",
    "    # print the symbol which is being downloaded\n",
    "    print( str(list_tickers.index(i)) + str(' : ') + i, sep=',', end=',', flush=True)  \n",
    "    \n",
    "    try:\n",
    "        # download the stock price \n",
    "        stock = []\n",
    "        stock = yf.download(i,start=start, end=end, progress=False)\n",
    "        \n",
    "        # append the individual stock prices \n",
    "        if len(stock) == 0:\n",
    "            None\n",
    "        else:\n",
    "            stock['ticker']=i\n",
    "            stock_final = stock_final.append(stock,sort=False)\n",
    "    except Exception:\n",
    "        None\n",
    "        \n",
    "stock_final['date']=stock_final.index\n",
    "stock_final['quarter'] = stock_final['date'].dt.to_period('Q')\n",
    "stock_final['market_cap']=stock_final['Adj Close']*stock_final['Volume']\n",
    "stock_final=stock_final.drop(columns=['Open', 'High','Low','Close','date','Adj Close','Volume'])\n",
    "display(stock_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_final = stock_final.groupby(['ticker','quarter']).sum()\n",
    "stock_final['percent_change']=stock_final['market_cap'].pct_change()\n",
    "display(stock_final)\n",
    "Quarter = stock_final.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37de3b",
   "metadata": {},
   "source": [
    "# Text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977797f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "n= len(texts)\n",
    "texts = [processing(x) for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23086a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N=len(texts)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    # creating objects\n",
    "    text=texts[i]\n",
    "    emo = LeXmo.LeXmo(text)\n",
    "    emo.pop('text', None)\n",
    "    emo_array = np.array(list(emo.items()))\n",
    "    score = emo_array[:,1]\n",
    "    if i==0:\n",
    "        con = score\n",
    "    else :\n",
    "        con = np.vstack((con, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "score = np.reshape(con, (n, 10))\n",
    "column=['anger','anticipation','disgust','fear','joy','negative','positive','sadness','surprise','trust']\n",
    "df = pd.DataFrame(score, columns = column)\n",
    "df[column]=df[column].astype(float)\n",
    "\n",
    "#number_words = np.zeros(n)\n",
    "#for i in range(n):\n",
    "#    number_words[i] = len(texts[i])\n",
    "#df['number_words']=number_words\n",
    "df['id'] = list_ids\n",
    "df['date']=list_ids\n",
    "df=df.replace({'date': id_to_date})\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "#df['quarter'] = Quarter\n",
    "df['ticker']= Ticker\n",
    "df= df.sort_values(by=['ticker','date'], ascending=True)\n",
    "# Remove most recent text for each ticker\n",
    "df=df.drop(df.groupby('ticker').tail(1).index, axis=0)\n",
    "# Add quarters\n",
    "df['quarter']=Quarter\n",
    "df_final=df\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ca274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_change = df_final\n",
    "column_change=['anger_change','anticipation_change','disgust_change','fear_change','joy_change','negative_change','positive_change','sadness_change','surprise_change','trust_change']\n",
    "df_change[column] = df[column].pct_change()\n",
    "#df_change.columns =column_change\n",
    "df_change = df_change.drop(columns=['id','date'])\n",
    "df_change = df_change.groupby(['ticker','quarter']).sum()\n",
    "display(df_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb446a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "df_change = pd.merge(stock_final, df_change, left_index=True, right_index=True)\n",
    "# Drop first row\n",
    "df_change=df_change.drop(df_change.groupby('ticker').head(1).index, axis=0)\n",
    "display(df_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da439fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols\n",
    "result = sm.ols(formula=\"percent_change ~ anger+anticipation+fear+joy+negative+positive+sadness+surprise+trust\", data=df_change).fit()\n",
    "#anger+anticipation+disgust+fear+joy+negative+positive+sadness+surprise+trust\n",
    "# ATTENTION NAN DANS DiSGUST\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87630f03",
   "metadata": {},
   "source": [
    "# In number of words ==> better to keep frequency\n",
    "\n",
    "df[column]=df[column].multiply(df[\"number_words\"], axis = \"index\")\n",
    "#df[[\"A\", \"B\"]].multiply(df[\"C\"], axis=\"index\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = pd.DataFrame(df[column].mean())\n",
    "df_mean.columns = ['Average frequency']\n",
    "ax = df_mean.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f9ebb",
   "metadata": {},
   "source": [
    "# Stock returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cd9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580daa15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f77b6520",
   "metadata": {},
   "source": [
    "# A faire pour cette m√©thode : \n",
    "- classer les earning calls par quarter et par stock index\n",
    "- importer les stock returns et garder seulement ceux des earning calls (mapping permno/ stock index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75715b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e6cad8",
   "metadata": {},
   "source": [
    "# liens utiles\n",
    "\n",
    "https://betterprogramming.pub/unlocking-emotions-in-text-using-python-6d062b48d71f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ef4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
