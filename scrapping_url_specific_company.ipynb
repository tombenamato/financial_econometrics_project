{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1640f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries as needed\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver   # for webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # for implicit and explict waits\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm.notebook import tqdm # to create loadbard in for loop\n",
    "import os\n",
    "from datetime import date\n",
    "import time\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a1352",
   "metadata": {},
   "source": [
    "# Description of the file\n",
    "This fille scrap all the earning call of the s&p 500, it would take around 18 hour to dowload for the 500.\n",
    "One can choose to dowload it overnight partly, and when want to stop just kill the kernel.\n",
    "Indeed if an error occured, a tracking system of what have already been downloaded exist. So when resuming later it will start from where it left roughly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86c161",
   "metadata": {},
   "source": [
    "### url to use for apple\n",
    "first call\n",
    "\n",
    "https://seekingalpha.com/api/v3/symbols/aapl/transcripts?filter[until]=undefined&id=aapl&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=true&page[size]=20\n",
    "\n",
    "next call \n",
    "\n",
    "https://seekingalpha.com/api/v3/symbols/aapl/transcripts?filter[until]=1501632962&id=aapl&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=false&page[size]=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29a3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_for_scrap(ticker, publish_time_min ):\n",
    "    # accept publis_time_min = None\n",
    "    return_per_request  = 20 #the one used by seekingalpha by default\n",
    "    ticker = ticker.lower()\n",
    "    publish_time_min = \"undefined\" if publish_time_min == \"None\" else str(publish_time_min)\n",
    "    to_return = (\"https://seekingalpha.com/api/v3/symbols/\"+ticker+\"/transcripts?filter[until]=\"+publish_time_min\n",
    "                 +\"&id=\"+ticker\n",
    "                 +\"&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=true&page[size]=\"\n",
    "                 + str(return_per_request))\n",
    "    return to_return\n",
    "def is_earning_call(element_response):\n",
    "    title = element_response[\"attributes\"][\"title\"].lower()\n",
    "    has_earning_in_title = \"earning\" in title or \"earnings\" in title\n",
    "    has_call_in_title = \"call\" in title\n",
    "    return element_response[\"type\"]==\"transcript\" and has_call_in_title and has_earning_in_title\n",
    "def get_url_id_date_earning_call(element_response):\n",
    "    date = element_response[\"attributes\"][\"publishOn\"][:10]\n",
    "    call_id = element_response[\"id\"]\n",
    "    url = element_response[\"links\"][\"self\"]\n",
    "    return url, call_id, date\n",
    "def open_brower():\n",
    "    service = Service(executable_path)\n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_argument(\"--enable-javascript\")\n",
    "    driver = webdriver.Chrome(service=service,options=option)\n",
    "    return driver\n",
    "def get_api_response(driver,url):\n",
    "    driver.get(url)\n",
    "    json_response = driver.find_element(by=By.TAG_NAME, value = \"body\").text\n",
    "    return json.loads(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7d0ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM' 'AOS' 'ABT' 'ABBV' 'ABMD' 'ACN' 'ATVI' 'ADM' 'ADBE' 'ADP' 'AAP'\n",
      " 'AES' 'AFL' 'A' 'AIG' 'APD' 'AKAM' 'ALK' 'ALB' 'ARE' 'ALGN' 'ALLE' 'LNT'\n",
      " 'ALL' 'GOOGL' 'GOOG' 'MO' 'AMZN' 'AMCR' 'AMD' 'AEE' 'AAL' 'AEP' 'AXP'\n",
      " 'AMT' 'AWK' 'AMP' 'ABC' 'AME' 'AMGN' 'APH' 'ADI' 'ANSS' 'ANTM' 'AON'\n",
      " 'APA' 'AAPL' 'AMAT' 'APTV' 'ANET' 'AIZ' 'T' 'ATO' 'ADSK' 'AZO' 'AVB'\n",
      " 'AVY' 'BKR' 'BALL' 'BAC' 'BBWI' 'BAX' 'BDX' 'WRB' 'BRK.B' 'BBY' 'BIO'\n",
      " 'TECH' 'BIIB' 'BLK' 'BK' 'BA' 'BKNG' 'BWA' 'BXP' 'BSX' 'BMY' 'AVGO' 'BR'\n",
      " 'BRO' 'BF.B' 'CHRW' 'CDNS' 'CZR' 'CPT' 'CPB' 'COF' 'CAH' 'KMX' 'CCL'\n",
      " 'CARR' 'CTLT' 'CAT' 'CBOE' 'CBRE' 'CDW' 'CE' 'CNC' 'CNP' 'CDAY' 'CERN'\n",
      " 'CF' 'CRL' 'SCHW' 'CHTR' 'CVX' 'CMG' 'CB' 'CHD' 'CI' 'CINF' 'CTAS' 'CSCO'\n",
      " 'C' 'CFG' 'CTXS' 'CLX' 'CME' 'CMS' 'KO' 'CTSH' 'CL' 'CMCSA' 'CMA' 'CAG'\n",
      " 'COP' 'ED' 'STZ' 'CEG' 'COO' 'CPRT' 'GLW' 'CTVA' 'COST' 'CTRA' 'CCI'\n",
      " 'CSX' 'CMI' 'CVS' 'DHI' 'DHR' 'DRI' 'DVA' 'DE' 'DAL' 'XRAY' 'DVN' 'DXCM'\n",
      " 'FANG' 'DLR' 'DFS' 'DISH' 'DIS' 'DG' 'DLTR' 'D' 'DPZ' 'DOV' 'DOW' 'DTE'\n",
      " 'DUK' 'DRE' 'DD' 'DXC' 'EMN' 'ETN' 'EBAY' 'ECL' 'EIX' 'EW' 'EA' 'EMR'\n",
      " 'ENPH' 'ETR' 'EOG' 'EPAM' 'EFX' 'EQIX' 'EQR' 'ESS' 'EL' 'ETSY' 'RE'\n",
      " 'EVRG' 'ES' 'EXC' 'EXPE' 'EXPD' 'EXR' 'XOM' 'FFIV' 'FDS' 'FAST' 'FRT'\n",
      " 'FDX' 'FITB' 'FRC' 'FE' 'FIS' 'FISV' 'FLT' 'FMC' 'F' 'FTNT' 'FTV' 'FBHS'\n",
      " 'FOXA' 'FOX' 'BEN' 'FCX' 'AJG' 'GRMN' 'IT' 'GE' 'GNRC' 'GD' 'GIS' 'GPC'\n",
      " 'GILD' 'GL' 'GPN' 'GM' 'GS' 'GWW' 'HAL' 'HIG' 'HAS' 'HCA' 'PEAK' 'HSIC'\n",
      " 'HSY' 'HES' 'HPE' 'HLT' 'HOLX' 'HD' 'HON' 'HRL' 'HST' 'HWM' 'HPQ' 'HUM'\n",
      " 'HII' 'HBAN' 'IEX' 'IDXX' 'ITW' 'ILMN' 'INCY' 'IR' 'INTC' 'ICE' 'IBM'\n",
      " 'IP' 'IPG' 'IFF' 'INTU' 'ISRG' 'IVZ' 'IPGP' 'IQV' 'IRM' 'JBHT' 'JKHY' 'J'\n",
      " 'JNJ' 'JCI' 'JPM' 'JNPR' 'K' 'KEY' 'KEYS' 'KMB' 'KIM' 'KMI' 'KLAC' 'KHC'\n",
      " 'KR' 'LHX' 'LH' 'LRCX' 'LW' 'LVS' 'LDOS' 'LEN' 'LLY' 'LNC' 'LIN' 'LYV'\n",
      " 'LKQ' 'LMT' 'L' 'LOW' 'LUMN' 'LYB' 'MTB' 'MRO' 'MPC' 'MKTX' 'MAR' 'MMC'\n",
      " 'MLM' 'MAS' 'MA' 'MTCH' 'MKC' 'MCD' 'MCK' 'MDT' 'MRK' 'FB' 'MET' 'MTD'\n",
      " 'MGM' 'MCHP' 'MU' 'MSFT' 'MAA' 'MRNA' 'MHK' 'MOH' 'TAP' 'MDLZ' 'MPWR'\n",
      " 'MNST' 'MCO' 'MS' 'MOS' 'MSI' 'MSCI' 'NDAQ' 'NTAP' 'NFLX' 'NWL' 'NEM'\n",
      " 'NWSA' 'NWS' 'NEE' 'NLSN' 'NKE' 'NI' 'NDSN' 'NSC' 'NTRS' 'NOC' 'NLOK'\n",
      " 'NCLH' 'NRG' 'NUE' 'NVDA' 'NVR' 'NXPI' 'ORLY' 'OXY' 'ODFL' 'OMC' 'OKE'\n",
      " 'ORCL' 'OGN' 'OTIS' 'PCAR' 'PKG' 'PARA' 'PH' 'PAYX' 'PAYC' 'PYPL' 'PENN'\n",
      " 'PNR' 'PEP' 'PKI' 'PFE' 'PM' 'PSX' 'PNW' 'PXD' 'PNC' 'POOL' 'PPG' 'PPL'\n",
      " 'PFG' 'PG' 'PGR' 'PLD' 'PRU' 'PEG' 'PTC' 'PSA' 'PHM' 'PVH' 'QRVO' 'PWR'\n",
      " 'QCOM' 'DGX' 'RL' 'RJF' 'RTX' 'O' 'REG' 'REGN' 'RF' 'RSG' 'RMD' 'RHI'\n",
      " 'ROK' 'ROL' 'ROP' 'ROST' 'RCL' 'SPGI' 'CRM' 'SBAC' 'SLB' 'STX' 'SEE'\n",
      " 'SRE' 'NOW' 'SHW' 'SBNY' 'SPG' 'SWKS' 'SJM' 'SNA' 'SEDG' 'SO' 'LUV' 'SWK'\n",
      " 'SBUX' 'STT' 'STE' 'SYK' 'SIVB' 'SYF' 'SNPS' 'SYY' 'TMUS' 'TROW' 'TTWO'\n",
      " 'TPR' 'TGT' 'TEL' 'TDY' 'TFX' 'TER' 'TSLA' 'TXN' 'TXT' 'TMO' 'TJX' 'TSCO'\n",
      " 'TT' 'TDG' 'TRV' 'TRMB' 'TFC' 'TWTR' 'TYL' 'TSN' 'USB' 'UDR' 'ULTA' 'UAA'\n",
      " 'UA' 'UNP' 'UAL' 'UNH' 'UPS' 'URI' 'UHS' 'VLO' 'VTR' 'VRSN' 'VRSK' 'VZ'\n",
      " 'VRTX' 'VFC' 'VTRS' 'V' 'VNO' 'VMC' 'WAB' 'WMT' 'WBA' 'WBD' 'WM' 'WAT'\n",
      " 'WEC' 'WFC' 'WELL' 'WST' 'WDC' 'WRK' 'WY' 'WHR' 'WMB' 'WTW' 'WYNN' 'XEL'\n",
      " 'XYL' 'YUM' 'ZBRA' 'ZBH' 'ZION' 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "# Get list of all S&P 500 tickers\n",
    "import pandas as pd\n",
    "table=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "df_tickers = table[0]\n",
    "df_tickers.to_csv('S&P500-Info.csv')\n",
    "df_tickers.to_csv(\"S&P500-Symbols.csv\", columns=['Symbol'])\n",
    "tickers=df_tickers[\"Symbol\"].values\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e04f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory data/ticker/MMM has been created!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 8] Exec format error: './chromedriver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47488/440000777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmore_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#open driver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_brower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mid_URLs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mid_to_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_47488/4243199370.py\u001b[0m in \u001b[0;36mopen_brower\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChromeOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--enable-javascript\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_api_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m                                         \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                                         \u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_capabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                                         service_log_path, service, keep_alive)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             creationflags=self.creationflags)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    798\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1549\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 8] Exec format error: './chromedriver'"
     ]
    }
   ],
   "source": [
    "executable_path = \"./chromedriver\" #specify the right file for your os, i.e. linux, macOS ...\n",
    "for ticker in tickers:\n",
    "    html_path = \"data/ticker/\"+ticker\n",
    "    last_time_scrap_path =html_path+ \"/last_time_scrap\"\n",
    "    if not os.path.exists(html_path):\n",
    "        os.makedirs(html_path)\n",
    "        print(f\"The new directory {html_path} has been created!\")\n",
    "    if os.path.exists(last_time_scrap_path):\n",
    "        with open(last_time_scrap_path, \"r\") as file:\n",
    "            publish_time_min = file.read()\n",
    "    else : \n",
    "        publish_time_min = \"None\"\n",
    "    if publish_time_min !=\"all\":\n",
    "        more_data = True\n",
    "        #open driver\n",
    "        driver = open_brower()\n",
    "        id_URLs = []\n",
    "        id_to_date = {}\n",
    "        while more_data:\n",
    "            url = create_url_for_scrap(ticker, publish_time_min)\n",
    "            data_responses = get_api_response(driver,url)\n",
    "            if \"meta\" not in data_responses:\n",
    "                # to make a clean new browser to start again, so if metada not related to an ip \n",
    "                # saved in order to flag bot will losse them\n",
    "                driver.quit()\n",
    "                time.sleep(5) # 2 chances to be flag as robot\n",
    "                driver = open_brower()\n",
    "                data_responses = get_api_response(driver, url)\n",
    "                if \"meta\" not in data_responses:\n",
    "                    last_publish_time_min = publish_time_min\n",
    "                    break\n",
    "            publish_time_min = str(data_responses[\"meta\"][\"page\"][\"minmaxPublishOn\"][\"min\"]) # need to be string\n",
    "            if publish_time_min!= 'None':\n",
    "                for element in data_responses[\"data\"]:\n",
    "                    # retrieve scrapped data\n",
    "                    if is_earning_call(element):\n",
    "                        URL, call_id, date = get_url_id_date_earning_call(element)\n",
    "                        id_URLs.append((call_id,URL))\n",
    "                        id_to_date[call_id] = date\n",
    "            else :\n",
    "                last_publish_time_min = \"all\"\n",
    "                more_data = False\n",
    "            time.sleep(5+random.uniform(0, 1))\n",
    "    # to make a clean new browser for each ticker, so if metada not related to an ip \n",
    "    # saved in order to flag bot will losse them\n",
    "    driver.quit()\n",
    "    # Download HTML files\n",
    "    domain_name = 'https://seekingalpha.com'\n",
    "    for call_id, URL in tqdm(id_URLs):\n",
    "        file_path = html_path + \"/\"+ call_id + \".html\"\n",
    "        with open(file_path, \"w\") as file :\n",
    "            url = domain_name+URL\n",
    "            html =  requests.get(url).text\n",
    "            file.write(html)\n",
    "            \n",
    "    # Save the last scrapped url of the ticker, so that if bot detected can resume\n",
    "    with open(html_path+\"/last_time_scrap\", \"w\") as file:\n",
    "        file.write(last_publish_time_min)    \n",
    "    \n",
    "    # Save date of transcripts\n",
    "    id_to_date_path = \"data/ticker/id_to_date\"\n",
    "    if not os.path.exists(id_to_date_path):\n",
    "        file_id_to_date = {}\n",
    "    else:\n",
    "        with open(id_to_date_path,\"rb\") as file :\n",
    "            file_id_to_date = pickle.load(file)\n",
    "    for call_id, date in id_to_date.items():\n",
    "        file_id_to_date[call_id] = date\n",
    "\n",
    "    with open(id_to_date_path,\"wb\") as file : \n",
    "        pickle.dump(file_id_to_date, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    time.sleep(30+random.uniform(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be399e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BeautifulSoup(html).get_text()[:2000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
