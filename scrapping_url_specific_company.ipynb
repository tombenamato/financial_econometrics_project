{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1640f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries as needed\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver   # for webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # for implicit and explict waits\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm.notebook import tqdm # to create loadbard in for loop\n",
    "import os\n",
    "from datetime import date\n",
    "import time\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13033aed",
   "metadata": {},
   "source": [
    "For now dowload all earning call transcript for a specified ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a1352",
   "metadata": {},
   "source": [
    "### url to use for apple\n",
    "https://seekingalpha.com/api/v3/symbols/aapl/transcripts?filter[until]=undefined&id=aapl&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=true&page[size]=20\n",
    "\n",
    "https://seekingalpha.com/api/v3/symbols/aapl/transcripts?filter[until]=1501632962&id=aapl&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=false&page[size]=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29a3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_for_scrap(ticker, publish_time_min ):\n",
    "    # accept publis_time_min = None\n",
    "    return_per_request  = 20 #the one used by seekingalpha by default\n",
    "    ticker = ticker.lower()\n",
    "    publish_time_min = \"undefined\" if publish_time_min ==None else str(publish_time_min)\n",
    "    to_return = (\"https://seekingalpha.com/api/v3/symbols/\"+ticker+\"/transcripts?filter[until]=\"+publish_time_min\n",
    "                 +\"&id=\"+ticker\n",
    "                 +\"&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=true&page[size]=\"\n",
    "                 + str(return_per_request))\n",
    "    return to_return\n",
    "def is_earning_call(element_response):\n",
    "    return element_response[\"type\"]==\"transcript\"\n",
    "def get_url_id_date_earning_call(element_response):\n",
    "    date = element_response[\"attributes\"][\"publishOn\"][:10]\n",
    "    call_id = element_response[\"id\"]\n",
    "    url = element_response[\"links\"][\"self\"]\n",
    "    return url, call_id, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e04f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now scrapp all earning call transcript from one company\n",
    "ticker = \"APLE\" #Apple hospitality REIT, Inc.\n",
    "html_path = \"data/ticker/\"+ticker ## todo save file with name time step*\n",
    "last_time_scrap_path =html_path+ \"/last_time_scrap\"\n",
    "if not os.path.exists(html_path):\n",
    "    os.makedirs(html_path)\n",
    "    print(f\"The new directory {html_path} has been created!\")\n",
    "if os.path.exists(last_time_scrap_path):\n",
    "    with open(last_time_scrap_path, \"r\") as file:\n",
    "        publish_time_min = file.read()\n",
    "else : \n",
    "    publish_time_min = None\n",
    "if publish_time_min !=\"all\":\n",
    "    more_data = True\n",
    "    executable_path = \"./chromedriver_linux\"\n",
    "    service = Service(executable_path)\n",
    "    option = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service,options=option)\n",
    "    id_URLs = []\n",
    "    id_to_date = {}\n",
    "    while more_data:\n",
    "        url = create_url_for_scrap(ticker, publish_time_min)\n",
    "        driver.get(url)\n",
    "        json_response = driver.find_element(by=By.TAG_NAME, value = \"body\").text\n",
    "        data_responses = json.loads(json_response)\n",
    "        if \"meta\" not in data_responses:\n",
    "            time.sleep(5) # 2 chances to be flag as robot\n",
    "            driver.get(url)\n",
    "            json_response = driver.find_element(by=By.TAG_NAME, value = \"body\").text\n",
    "            data_responses = json.loads(json_response)\n",
    "            if \"meta\" not in data_responses:\n",
    "                last_publish_time_min = publish_time_min\n",
    "                break\n",
    "        publish_time_min = str(data_responses[\"meta\"][\"page\"][\"minmaxPublishOn\"][\"min\"]) # need to be string\n",
    "        if publish_time_min!= 'None':\n",
    "            for element in data_responses[\"data\"]:\n",
    "                if is_earning_call(element):\n",
    "                    URL, call_id, date = get_url_id_date_earning_call(element)\n",
    "                    id_URLs.append((call_id,URL))\n",
    "                    id_to_date[call_id] = date\n",
    "        else :\n",
    "            last_publish_time_min = \"all\"\n",
    "            more_data = False\n",
    "        time.sleep(2+random.uniform(0, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9856200",
   "metadata": {},
   "source": [
    "\n",
    " TODO list:\n",
    " \n",
    " [x] save the last fetch publish time into specific ticker folder, so that if block can continue not from the start\n",
    " \n",
    " [x] download the hmtl files and save them into specific ticker folder\n",
    " \n",
    " [ ] save the dictionary id_to_date into data/ticker file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb4ff2",
   "metadata": {},
   "source": [
    "Save the last scrapped url of the ticker, so that if bot detected can resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86290a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(html_path+\"/last_time_scrap\", \"w\") as file:\n",
    "    file.write(last_publish_time_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ebb86",
   "metadata": {},
   "source": [
    "Download HTML files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1225433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb42045ffc2d4d8ca22e7b00d22e04a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_name = 'https://seekingalpha.com'\n",
    "for call_id, URL in tqdm(id_URLs):\n",
    "    file_path = html_path + \"/\"+ call_id + \".html\"\n",
    "    with open(file_path, \"w\") as file :\n",
    "        url = domain_name+URL\n",
    "        html =  requests.get(url).text\n",
    "        file.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b0260",
   "metadata": {},
   "source": [
    "## Check last file got downloaded, i.e. captcha/bot error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b9b9e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apple Hospitality REIT's (APLE) CEO Justin Knight on Q1 2016 Results - Earnings Call Transcript | Seeking Alpha                    Seeking Alpha - Go to HomepageTranscriptsFinancialApple Hospitality REIT's (APLE) CEO Justin Knight on Q1 2016 Results - Earnings Call TranscriptMay 06, 2016 2:20 PM ETApple Hospitality REIT, Inc. (APLE)SA Transcripts127.16K FollowersFollowApple Hospitality REIT, Inc. (NYSE:APLE) Q1 2016 Earnings Conference Call May 6, 2016 9:00 AM ET Executives Kelly Clarke - VP, IR Justin Knight - President & CEO Krissy Gathright - COO Bryan Peery - CFO Analysts Ryan Meliker - Canaccord Genuity Jeff Donnelly - Wells Fargo Daniel Donlan - Ladenberg Thalman Bryan Maher - FBR Blair Brantley - BB&T Operator Greetings, and welcome to the Apple Hospitality REIT First Quarter 2016 Earnings Conference Call. [Operator Instructions]  As a reminder, this conference is being recorded. It is now my pleasure to introduce your host Kelly Clarke, Vice President, Investor Relations. Thank you. You may begin. Kelly Clarke Thank you. Good morning, and welcome to Apple Hospitality REIT's first quarter 2016 earnings call on this, the 6th day of May 2016. Today's call will be based on the first quarter 2016 earnings release, which was distributed yesterday afternoon. I would like to remind everyone that today's call will contain forward-looking statements as defined by federal securities laws, including statements regarding future operating results. These statements involve known and unknown risks and other factors which may cause actual results, performance or achievements of Apple Hospitality to be materially different from future results, performance or achievements expressed or implied by such forward-looking statements. Participants should carefully review our financial statements and the notes thereto, as well as the risk factors described in Apple Hospitality's 2015 Form 10-K, first quarter 2016 Form 10-Q and other filings with the SEC. Any forward-looking statement \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(html).get_text()[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aac81f",
   "metadata": {},
   "source": [
    "Save date of transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "377c369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_date_path = \"data/ticker/id_to_date\"\n",
    "if not os.path.exists(id_to_date_path):\n",
    "    file_id_to_date = {}\n",
    "else:\n",
    "    with open(id_to_date_path,\"rb\") as file :\n",
    "        file_id_to_date = pickle.load(file)\n",
    "for call_id, date in id_to_date.items():\n",
    "    file_id_to_date[call_id] = date\n",
    "    \n",
    "with open(id_to_date_path,\"wb\") as file : \n",
    "    pickle.dump(file_id_to_date, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e133216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
