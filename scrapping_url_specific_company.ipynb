{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1640f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries as needed\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver   # for webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # for implicit and explict waits\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm.notebook import tqdm # to create loadbard in for loop\n",
    "import os\n",
    "from datetime import date\n",
    "import time\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13033aed",
   "metadata": {},
   "source": [
    "For now dowload all earning call transcript for a specified ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a1352",
   "metadata": {},
   "source": [
    "### url to use for apple\n",
    "https://seekingalpha.com/api/v3/symbols/aapl/transcripts?filter[until]=undefined&id=aapl&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=true&page[size]=20\n",
    "\n",
    "https://seekingalpha.com/api/v3/symbols/aapl/transcripts?filter[until]=1501632962&id=aapl&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=false&page[size]=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29a3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url_for_scrap(ticker, publish_time_min ):\n",
    "    # accept publis_time_min = None\n",
    "    return_per_request  = 20 #the one used by seekingalpha by default\n",
    "    ticker = ticker.lower()\n",
    "    publish_time_min = \"undefined\" if publish_time_min ==None else str(publish_time_min)\n",
    "    to_return = (\"https://seekingalpha.com/api/v3/symbols/\"+ticker+\"/transcripts?filter[until]=\"+publish_time_min\n",
    "                 +\"&id=\"+ticker\n",
    "                 +\"&include=author%2CprimaryTickers%2CsecondaryTickers%2Csentiments&isMounting=true&page[size]=\"\n",
    "                 + str(return_per_request))\n",
    "    return to_return\n",
    "def is_earning_call(element_response):\n",
    "    title = element_response[\"attributes\"][\"title\"].lower()\n",
    "    has_earning_in_title = \"earning\" in title or \"earnings\" in title\n",
    "    has_call_in_title = \"call\" in title\n",
    "    return element_response[\"type\"]==\"transcript\" and has_call_in_title and has_earning_in_title\n",
    "def get_url_id_date_earning_call(element_response):\n",
    "    date = element_response[\"attributes\"][\"publishOn\"][:10]\n",
    "    call_id = element_response[\"id\"]\n",
    "    url = element_response[\"links\"][\"self\"]\n",
    "    return url, call_id, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e04f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory data/ticker/AAPL has been created!\n"
     ]
    }
   ],
   "source": [
    "# for now scrapp all earning call transcript from one company\n",
    "ticker = \"AAPL\" #Apple hospitality REIT, Inc.\n",
    "html_path = \"data/ticker/\"+ticker ## todo save file with name time step*\n",
    "last_time_scrap_path =html_path+ \"/last_time_scrap\"\n",
    "if not os.path.exists(html_path):\n",
    "    os.makedirs(html_path)\n",
    "    print(f\"The new directory {html_path} has been created!\")\n",
    "if os.path.exists(last_time_scrap_path):\n",
    "    with open(last_time_scrap_path, \"r\") as file:\n",
    "        publish_time_min = file.read()\n",
    "else : \n",
    "    publish_time_min = None\n",
    "if publish_time_min !=\"all\":\n",
    "    more_data = True\n",
    "    executable_path = \"./chromedriver_linux\"\n",
    "    service = Service(executable_path)\n",
    "    option = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service,options=option)\n",
    "    id_URLs = []\n",
    "    id_to_date = {}\n",
    "    while more_data:\n",
    "        url = create_url_for_scrap(ticker, publish_time_min)\n",
    "        driver.get(url)\n",
    "        json_response = driver.find_element(by=By.TAG_NAME, value = \"body\").text\n",
    "        data_responses = json.loads(json_response)\n",
    "        if \"meta\" not in data_responses:\n",
    "            time.sleep(5) # 2 chances to be flag as robot\n",
    "            driver.get(url)\n",
    "            json_response = driver.find_element(by=By.TAG_NAME, value = \"body\").text\n",
    "            data_responses = json.loads(json_response)\n",
    "            if \"meta\" not in data_responses:\n",
    "                last_publish_time_min = publish_time_min\n",
    "                break\n",
    "        publish_time_min = str(data_responses[\"meta\"][\"page\"][\"minmaxPublishOn\"][\"min\"]) # need to be string\n",
    "        if publish_time_min!= 'None':\n",
    "            for element in data_responses[\"data\"]:\n",
    "                if is_earning_call(element):\n",
    "                    URL, call_id, date = get_url_id_date_earning_call(element)\n",
    "                    id_URLs.append((call_id,URL))\n",
    "                    id_to_date[call_id] = date\n",
    "        else :\n",
    "            last_publish_time_min = \"all\"\n",
    "            more_data = False\n",
    "        time.sleep(2+random.uniform(0, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ebb86",
   "metadata": {},
   "source": [
    "Download HTML files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1225433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa980f525f54f2a9740c355a56ab453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_name = 'https://seekingalpha.com'\n",
    "for call_id, URL in tqdm(id_URLs):\n",
    "    file_path = html_path + \"/\"+ call_id + \".html\"\n",
    "    with open(file_path, \"w\") as file :\n",
    "        url = domain_name+URL\n",
    "        html =  requests.get(url).text\n",
    "        file.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edf351",
   "metadata": {},
   "source": [
    "Save the last scrapped url of the ticker, so that if bot detected can resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db41eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(html_path+\"/last_time_scrap\", \"w\") as file:\n",
    "    file.write(last_publish_time_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b0260",
   "metadata": {},
   "source": [
    "## Check last file got downloaded, i.e. captcha/bot error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9b9e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apple F1Q06 (Qtr End 12/31/2005) Earnings Conference Call Transcript | Seeking Alpha                    Seeking Alpha - Go to HomepageTranscriptsTechnologyApple F1Q06 (Qtr End 12/31/2005) Earnings Conference Call TranscriptJan. 19, 2006 8:52 AM ETApple Inc. (AAPL)SA Transcripts127.16K FollowersFollow Apple Computer, Inc. (NASDAQ:AAPL) Q1 2006 Financial Results Conference Call January 18th 2006, 5:00 PM. Executives Nancy Paxton, Senior Director, Investor Relations and Corporate Finance Peter Oppenheimer, Chief Financial Officer Timothy (Tim) Cook, Chief Operating Officer Gary Whistler, Corporate Treasurer Analysts Keith Bachman Banc of America Securities. Benjamin Reitzes, UBS. Robert Semple, Credit Suisse First Boston Gene Munster, Piper Jaffray. Rebecca Runkle, Morgan Stanley. Bill Shope, J.P.Morgan. Charles Wolf, Needham & Company. Joel Wagonfeld, First Albany Capital. Richard Chu, Sg. Cowen & Co. Steve Lidberg, Pacific Crest Securities. Shaw Wu, American Technology. Steven Fortuna, Prudential Equity Group David Bailey, Goldman Sachs. Shannon Cross, Cross Research Richard Gardner, Citigroup. Operator Good day and welcome to the Apple Computer's First Quarter Financial Results Conference Call. Today’s call is being recorded. At this time for opening remarks and introductions I would like to turn the call over to Ms. Nancy Paxton, Senior Director, Investor Relations and Corporate Finance. Please go ahead Ms. Paxton. Nancy Paxton, Senior Director, Investor Relations and Corporate Finance Good afternoon. Thanks for everyone for joining us. Speaking today is Apple’s CFO Peter Oppenheimer and he will be joined by Apple’s COO Timothy (Tim) Cook and corporate treasurer Gary Whistler for Q&A session with analyst. Please note that some of the information you will here during this call consists of forward looking statements regarding revenue gross margin, operating expenses, other income and expense, taxes earnings per share, Apple’s retail initiative, iPod shipments, future\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(html).get_text()[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aac81f",
   "metadata": {},
   "source": [
    "Save date of transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377c369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_date_path = \"data/ticker/id_to_date\"\n",
    "if not os.path.exists(id_to_date_path):\n",
    "    file_id_to_date = {}\n",
    "else:\n",
    "    with open(id_to_date_path,\"rb\") as file :\n",
    "        file_id_to_date = pickle.load(file)\n",
    "for call_id, date in id_to_date.items():\n",
    "    file_id_to_date[call_id] = date\n",
    "    \n",
    "with open(id_to_date_path,\"wb\") as file : \n",
    "    pickle.dump(file_id_to_date, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e133216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
