{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06adbad0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import the libraries as needed\n",
    "from selenium import webdriver\n",
    "from selenium import webdriver   # for webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # for implicit and explict waits\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm # to create loadbard in for loop\n",
    "import os\n",
    "from datetime import date\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70df0f8",
   "metadata": {},
   "source": [
    "## API data response\n",
    "\n",
    "<pre>\n",
    "dict( \n",
    "    data : list(one element is one earning call metada)\n",
    "    included : [first element don't care,{get id[id],get attributes{name:ticker}}] # corresponding data in order \n",
    "    meta : \"don't care for now\"\n",
    "        )\n",
    "</pre>\n",
    "One earning call metadata is show below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f97e3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/zvz37scs6vj6_wyjn348qj800000gn/T/ipykernel_3936/3999666461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mapi_json_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"body\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mapi_data_responses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_json_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mapi_included_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_json_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"included\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdict_included\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "# need to precise the option for date, nbr of metada for call transcript in the url paramater \n",
    "# https://en.wikipedia.org/wiki/Query_string\n",
    "nbr_earning_call_metada = 1500\n",
    "date_of_request = date.today().strftime(\"%Y-%m-%d\") #e.g. \"2022-04-28\"\n",
    "max_return_per_request = 50\n",
    "api_data_responses = []\n",
    "\n",
    "data_path = \"data/id_to_ticker\"\n",
    "if not os.path.exists(data_path):\n",
    "    id_mapping = {}\n",
    "else:\n",
    "    with open(data_path,\"rb\") as file :\n",
    "        id_mapping = pickle.load(file)\n",
    "\n",
    "for page_number in range(1,nbr_earning_call_metada//max_return_per_request + 1):\n",
    "    url = \"https://seekingalpha.com/api/v3/articles\"+\"?cacheBuster=\"\\\n",
    "          +str(date_of_request)\\\n",
    "          +\"&filter[category]=earnings%3A%3Aearnings-call-transcripts&filter[since]=0\"\\\n",
    "          +\"&filter[until]=0&include=author%2CprimaryTickers%2CsecondaryTickers&isMounting=true&page[size]=\"\\\n",
    "          +str(max_return_per_request)\\\n",
    "          +\"&page[number]=\"+str(page_number)\n",
    "    # the chrome driver depend on which version of chrome you are running specify the good one\n",
    "    executable_path = \"./chromedriver\"\n",
    "    service = Service(executable_path)\n",
    "    option = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service,options=option)\n",
    "    driver.get(url)\n",
    "    api_json_response = driver.find_element(by=By.TAG_NAME, value = \"body\").text\n",
    "    api_data_responses.extend(json.loads(api_json_response)[\"data\"])\n",
    "    api_included_responses = json.loads(api_json_response)[\"included\"]\n",
    "    dict_included = {}\n",
    "    \n",
    "    for element in api_included_responses:\n",
    "        dict_included[element[\"id\"]] = element[\"attributes\"]    \n",
    "    \n",
    "    for i in range(max_return_per_request):\n",
    "        ticker_id = api_data_responses[-50+i]\n",
    "        ticker_id = ticker_id[\"relationships\"][\"primaryTickers\"][\"data\"][0][\"id\"]\n",
    "        if ticker_id not in dict_included:\n",
    "            raise ValueError(\"The ticker id is not in the dictionnary included\")\n",
    "        ticker_included = dict_included[ticker_id][\"name\"]\n",
    "        id_mapping[api_data_responses[-50+i][\"id\"]] = ticker_included \n",
    "        \n",
    "with open(data_path,\"wb\") as file : \n",
    "    pickle.dump(id_mapping, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(url)\n",
    "#a quick loock of the result to check if we get results are get captcha/bot error \n",
    "print(api_json_response[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path,\"rb\") as file :\n",
    "    id_mapping = pickle.load(file)\n",
    "    print(len(id_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a446e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_responses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481c6b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id_and_path_to_earning_calls = [ (earning_call_metada[\"id\"] ,earning_call_metada[\"links\"][\"self\"]) \n",
    "                     for earning_call_metada in api_data_responses]\n",
    "# \"\"check url\n",
    "id_and_path_to_earning_calls[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4dbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/date\"\n",
    "if not os.path.exists(data_path):\n",
    "    date = {}\n",
    "else:\n",
    "    with open(data_path,\"rb\") as file :\n",
    "        date = pickle.load(file)\n",
    "for elem in api_data_responses:\n",
    "    date[elem[\"id\"]] = elem[\"attributes\"][\"publishOn\"][:10]\n",
    "    \n",
    "with open(data_path,\"wb\") as file : \n",
    "    pickle.dump(date, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(data_path,\"rb\") as file :\n",
    "    date = pickle.load(file)\n",
    "    print(date)\n",
    "    print(len(date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac1b14",
   "metadata": {},
   "source": [
    "## download all not yet download html from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9145a9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "domain_name = 'https://seekingalpha.com'\n",
    "data_path = \"data/article\"\n",
    "need_to_download = []\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    print(\"The new directory is created!\")\n",
    "for id_earning_call, path_to_earning_call in tqdm(id_and_path_to_earning_calls):\n",
    "    if not os.path.isfile(data_path+\"/\"+ id_earning_call +\".html\"):\n",
    "        # not in local directory\n",
    "        need_to_download.append((id_earning_call, path_to_earning_call))\n",
    "print(f\"Need to download {len(need_to_download)} html file(s)\")\n",
    "for id_earning_call, path_to_earning_call in tqdm(need_to_download):\n",
    "    with open(data_path+\"/\"+ id_earning_call+\".html\", \"x\") as file:\n",
    "            url = domain_name + path_to_earning_call\n",
    "            html_transcript = requests.get(url).text\n",
    "            file.write(html_transcript)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ae426",
   "metadata": {},
   "source": [
    "## Check last file got downloaded, i.e. captcha/bot error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "BeautifulSoup(html_transcript).get_text()[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e7e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
